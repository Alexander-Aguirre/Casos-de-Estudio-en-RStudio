                                         ###############################
                                         # Control Predictivo en SCADA #
                                         ###############################


######################################
# Instalacion y llamado de librerias #
######################################

# Instalacion de librerias:
install.packages("readr")
install.packages("caret")
install.packages("hplot")
install.packages("car")
install.packages("cluster")
install.packages("clValid")
install.packages("aricode")
install.packages('neuralnet')
install.packages("DMwR")

# Llamado de librerias:
library(readr)
library(corrplot)
library(caTools) #Permite hacer el "splitRatio"
library(ggplot2)
library(lattice)
library(caret) #Permite hacer el "scatterplotMatrix"
library(hplot)
library(car)
library(dendextend)
library(cluster)
library(clValid)
library(aricode)
library(plyr)
library(neuralnet)
library(DMwR)
library(Metrics)
library(neuralnet)
library(DMwR)

###########################
# Importacion del Dataset #
###########################

Turbina <- read_csv("C:/Users/DELL/Desktop/Turbina.csv", col_names = TRUE)
Turbina = data.frame(Turbina)
View(Turbina)

# Sistema SCADA, que se estaba haciendo el monitoreo de algunos parametros referente a
# una turbina.
# Presenta parametros como:
#   Fecha y hora
#   Nivel de potencia activa (kW)
#   Velocidad del viento (m/s)
#   Curva de potencia te�rica (KWh)
#   Direcci�n del viento (�)

                                        ##############################
                                        # Aprendizaje no supervisado #
                                        ##############################
#########################
# Seleccion de variables#
#########################


Turbina <- Turbina[,-c(1),drop=FALSE] #Eliminacion de la primera columna (1), si fuera la segunda fuera (2).
View(Turbina)

#############################################################
# Muestreo aleatorio simple (Cierta cantidad de instancias) #
#############################################################

set.seed(2) #Fijar un punto semilla


split = sample.split(Turbina$LV.ActivePower..kW., SplitRatio=0.1)
summary(split)

sam= subset(Turbina, split == TRUE)

# Graficas de tipo pareado, combinan todas las variables de una sola vez.

pairs(sam)

# IMAGEN 01 - Grafico pareado

c = cor(sam) # Correlaciones que existe entre cada variable
c
corrplot(c)

# IMAGEN 02 - Grafico de calor de las correlaciones de las variables

scatterplotMatrix(sam)

# IMAGEN 03 - Funciones de densidad de las variables

#################################
# Escalamiento Multidimensional #
#################################

# Matriz de distancias
d = dist(sam, method = "euclidean")

# Escalamiento miltidimencional a dos dimensiones (k=2), necesario en el caso que necesite graficar.
fit = cmdscale(d,eig=TRUE, k=2)
x = fit$points[,1] 
y = fit$points[,2]
plot(x,y)

# IMAGEN 04 - Representacion grafica de las variables en dos dimensiones

text(x, y, labels = row.names(iris), cex=1)

# IMAGEN 05 - Representacion grafica de las variables en dos dimensiones con etiquetas de las instancias

####################
# Algoritmo K-Means#
####################
# Al no tener clases, me dirijo a la creacion de grupos.

# Elbow
# Crea diferentes valores de k
wi = c()
for (i in 1:10) 
{
  g = kmeans(sam[,1:4],i) 
  wi[i] = g$tot.withinss
}
plot((1:length(wi)),wi, xlab="Numero de Clusters", ylab="Suma Cuadrados Internos", pch=19, col="red", type = "b")

# IMAGEN 06 - Representacion grafica del algoritmo Elbow

grupos = kmeans(sam,2)
g1 = grupos$cluster
g2 = grupos$size
plot(x,y,col=c("red","green3")[g1], main = "turbinas K-Means")

# IMAGEN 07 - Grafica K-Means

############################
# Algoritmo Jerarquico DHC #
############################

hc = hclust(d, method = "complete" )
clus3 = cutree(hc, 2)
dend = as.dendrogram(hc)
dend = color_branches(dend, 2)
colors = c("red", "green3")
plot(dend, fill = colors[clus3], cex = 0.1 , main = "Clustering Jerarquico")

# IMAGEN 08 - Dendograma o clusteinr Jerargico

                   ######################
                   # Validacion Interna #
                   ######################

##################
# Indice de Dunn #
##################

du1 = dunn(d,g1)
du1 
du2 = dunn(d,clus3)
du2

# du1=0.004857496
# du2=0.008473948

##########################
# Coeficiente de Silueta #
##########################

sil1 = silhouette(g1,d)
plot(sil1,col=1:2, border=NA)

# IMAGEN 09 - Coeficiente de silueta de K-Means

sil2 = silhouette(clus3,d)
plot(sil2,col=4:5, border=NA)

# IMAGEN 10 - Coeficiente de silueta de DHC

                   ######################
                   # Validacion Externa #
                   ######################
###############
# ARI-AMI-NMI #
###############

ground = g1 # Ground Truth

ARI= ARI(ground,clus3)
ARI
AMI= AMI(ground,clus3)
AMI
NMI= NMI(ground,clus3,variant = c("joint"))
NMI

                                           ###########################
                                           # Aprendizaje supervisado #
                                           ###########################

###########################
# RED NEURONAL (Regresion)#
###########################

set.seed(2)
ind_test = sample(nrow(sam), nrow(sam)/4) # 4 -> 100%/4=25%
test = sam[ind_test, ]
train = sam[-ind_test, ]

# Renombrar el nombre de las columnas

#   y  -> Fecha y hora
#   x1 -> Nivel de potencia activa (kW)
#   x2 -> Velocidad del viento (m/s)
#   x3 -> Curva de potencia te�rica (KWh)
#   x4 -> Direcci�n del viento (�)

colnames(train)= c ("y","x1","x2","x3")
train
colnames(test)= c ("y","x1","x2","x3")
test

# Entrenamiento Red Neuronal
train_scal=scale(train[,1:4]) 
ann = neuralnet(y ~ x1 + x2 + x3, train_scal, hidden = c(1))
plot(ann, rep = "best")


# IMAGEN 11 - Representacion grafica de la red neuronal

# Test Red Neuronal, calculo de la salida
test_scal=scale(test[,1:4]) # Para poder escalar
output = compute(ann, test_scal[ , c("x1","x2","x3")])

# Predicciones
result = data.frame(  Real = test_scal[,1], 
  Predicted = output$net.result)


# Proceso de desescalar a los valores iniciales
output_oring = unscale(output$net.result,test_scal)
output_oring

                               ###############################
                               # Evaluacion de Regresion SVM #
                               ###############################

error = result$Real-result$Predicted
error

SCE = sum(error^2) # Suma de cuadrados debido al error
SCE 

MAE = mae(result$Real,result$Predicted)
MAE

MSE = mse(result$Real,result$Predicted)
MSE 

RMSE = rmse(result$Real,result$Predicted)
RMSE 

# Metricas normalizadas

STC = sum((result$Real-(mean(result$Real)))^2)
STC 

SCR = STC-SCE
SCR  

r2 = SCR/STC
r2 

r2a = 1-(1-r2)*(length(result$Real)-1)/(length(result$Real)-(dim(test)[2]-1))
r2a 
