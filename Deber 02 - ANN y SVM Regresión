                                         ###############################                                   
                                         # Control Predictivo en SCADA #
                                         ###############################                                        
# Integrantes:
# Alexander Aguirre
# Gabriela Gallegos
# Carolina Torres

######################################
# Instalacion y llamado de librerias #
######################################

# Instalacion de librerias:
install.packages("readr")
install.packages("caret")
install.packages("hplot")
install.packages("car")
install.packages("cluster")
install.packages("clValid")
install.packages("aricode")
install.packages('neuralnet')
install.packages("DMwR")

# Llamado de librerias:
library(readr)
library(corrplot)
library(caTools) #Permite hacer el "splitRatio"
library(ggplot2)
library(lattice)
library(caret) #Permite hacer el "scatterplotMatrix"
library(hplot)
library(car)
library(dendextend)
library(cluster)
library(clValid)
library(aricode)
library(plyr)
library(neuralnet)
library(DMwR)
library(Metrics)
library(neuralnet)
library(DMwR)
library(e1071)


###########################
# Importacion del Dataset #
###########################

Turbina <- read_csv("C:/Users/DELL/Desktop/Turbina.csv", col_names = TRUE)
Turbina = data.frame(Turbina)
View(Turbina)

# Presenta parametros como:
#   Fecha y hora
#   Nivel de potencia activa (kW)
#   Velocidad del viento (m/s)
#   Curva de potencia teórica (KWh)
#   Dirección del viento (°)

###########################################
# Esquematizacion del proceso de analisis #
###########################################

tiempoANS <- proc.time() # Tiempo de ejecución del aprendizaje no supervisado

                                         ##############################
                                         # Aprendizaje no supervisado #
                                         ##############################
#########################
# Seleccion de variables#
#########################

Turbina <- Turbina[,-c(1),drop=FALSE] #Eliminacion de la primera columna (1), si fuera la segunda fuera (2).
View(Turbina)

#############################################################
# Muestreo aleatorio simple (Cierta cantidad de instancias) #
#############################################################


set.seed(2) #Fijar un punto semilla


split = sample.split(Turbina$LV.ActivePower..kW., SplitRatio=0.1)
summary(split)

#   Mode   FALSE    TRUE 
#logical   45477    5053 

# Se desea trabajar unicamente con los TRUE y descartar los FALSE.
# Variable "sam" de "Sample" o "Muestreo".

sam= subset(Turbina, split == TRUE)

# Graficas de tipo pareado, combinan todas las variables de una sola vez.

pairs(sam)

# IMAGEN 01 - Grafico pareado

c = cor(sam) # Correlaciones que existe entre cada variable
c
corrplot(c)

# IMAGEN 02 - Grafico de calor de las correlaciones de las variables

scatterplotMatrix(sam)

# IMAGEN 03 - Funciones de densidad de las variables

#################################
# Escalamiento Multidimensional #
#################################

# Matriz de distancias
d = dist(sam, method = "euclidean")

# Escalamiento miltidimencional a dos dimensiones (k=2), necesario en el caso que necesite graficar.
fit = cmdscale(d,eig=TRUE, k=2)
x = fit$points[,1] 
y = fit$points[,2]
plot(x,y)

# IMAGEN 04 - Representacion grafica de las variables en dos dimensiones

text(x, y, labels = row.names(iris), cex=1)

# IMAGEN 05 - Representacion grafica de las variables en dos dimensiones con etiquetas de las instancias

####################
# Algoritmo K-Means#
####################
# Al no tener clases, me dirijo a la creacion de grupos.

# Elbow
# Crea diferentes valores de k
wi = c()
for (i in 1:10) 
{
  g = kmeans(sam[,1:4],i) 
  wi[i] = g$tot.withinss
}
plot((1:length(wi)),wi, xlab="Numero de Clusters", ylab="Suma Cuadrados Internos", pch=19, col="red", type = "b")

# IMAGEN 06 - Representacion grafica del algoritmo Elbow

grupos = kmeans(sam,2)
g1 = grupos$cluster
g2 = grupos$size
plot(x,y,col=c("red","green3")[g1], main = "turbinas K-Means")

# IMAGEN 07 - Grafica K-Means

############################
# Algoritmo Jerarquico DHC #
############################

hc = hclust(d, method = "complete" )
clus3 = cutree(hc, 2)
dend = as.dendrogram(hc)
dend = color_branches(dend, 2)
colors = c("red", "green3")
plot(dend, fill = colors[clus3], cex = 0.1 , main = "Clustering Jerarquico")

# IMAGEN 08 - Dendograma o clusteinr Jerargico

                 ######################
                 # Validacion Interna #
                 ######################

##################
# Indice de Dunn #
##################

du1 = dunn(d,g1)
du1 
du2 = dunn(d,clus3)
du2

# du1=0.004857496
# du2=0.008473948

##########################
# Coeficiente de Silueta #
##########################

sil1 = silhouette(g1,d)
plot(sil1,col=1:2, border=NA)

# IMAGEN 09 - Coeficiente de silueta de K-Means

sil2 = silhouette(clus3,d)
plot(sil2,col=4:5, border=NA)

# IMAGEN 10 - Coeficiente de silueta de DHC

# Al ser una compactacion de clustering promedio de 0.7, describe que es una muy buena compactacion
# de instancias.
                  ######################
                  # Validacion Externa #
                  ######################
###############
# ARI-AMI-NMI #
###############

ground = g1 # Ground Truth

ARI= ARI(ground,clus3)
ARI
AMI= AMI(ground,clus3)
AMI
NMI= NMI(ground,clus3,variant = c("joint"))
NMI

# ARI = 0.8884438 -> es un muy buen agrupamiento.
# AMI = 0.8215394 -> super bueno su agrupamiento.
# NMI = 0.712887  -> buen agrupamiento.

# Los dos algoritmos de clustering, han encontrado similares resultados, por lo tanto para este caso
# se podria escoger cualquiera de los dos algoritmos.

proc.time() - tiempoANS
#  user  system elapsed 
#195.30  136.80  450.65

# user: tiempo de la CPU dedicado a la ejecucion de las instrucciones del proceso [segundos].
# system: tiempo de la CPU empleado por el sistema operativo [segundos].
# elapsed: tiempo transcurrido real desde que se inicio el proceso [segundos].

                                            ###########################
                                            # Aprendizaje supervisado #
                                            ###########################



###############################
# Red Neuronal Artificial ANN #
###############################

tiempoANN <- proc.time()

set.seed(2)
ind_test = sample(nrow(sam), nrow(sam)/4) 
test = sam[ind_test, ]
train = sam[-ind_test, ]

# Renombrar el nombre de las columnas

#   y  -> Fecha y hora
#   x1 -> Nivel de potencia activa (kW)
#   x2 -> Velocidad del viento (m/s)
#   x3 -> Curva de potencia teórica (KWh)
#   x4 -> Dirección del viento (°)

colnames(train)= c ("y","x1","x2","x3")
train
colnames(test)= c ("y","x1","x2","x3")
test

# Entrenamiento Red Neuronal
train_scal=scale(train[,1:4]) # Para poder escalar desde la variable 1 a la 4 todas las filas.
ann = neuralnet(y ~ x1 + x2 + x3, train_scal, hidden = c(1)) # Una capa oculta, con una neurona.
plot(ann, rep = "best")


# IMAGEN 11 - Representacion grafica de la red neuronal

# Test Red Neuronal, calculo de la salida
test_scal=scale(test[,1:4]) # Para poder escalar
output = compute(ann, test_scal[ , c("x1","x2","x3")])

# Predicciones
result = data.frame(  Real = test_scal[,1], 
                      Predicted = output$net.result)

# La potencia activa vendria a ser las predicciones de resultados, sin embargo el problema surgiria al no
# saber el valor real dibido a que esta escalado.

# Proceso de desescalar a los valores iniciales
output_oring = unscale(output$net.result,test_scal)
output_oring

                               ###############################
                               # Evaluacion de Regresion ANN #
                               ###############################

error1 = result$Real-result$Predicted
error1

SCE1 = sum(error1^2) # Suma de cuadrados debido al error
SCE1 # 102.3744 -> El error no es tan pequeno, pero al considerar la cantidad de instancias no es considerable el error.

MAE1 = mae(result$Real,result$Predicted)
MAE1 #  0.1184078 -> Al ser valores muy bajos indican que el modelo es muy bueno.

MSE1 = mse(result$Real,result$Predicted)
MSE1 # 0.08105654 ->  Al ser valores muy bajos indican que el modelo es muy bueno.

RMSE1 = rmse(result$Real,result$Predicted)
RMSE1 # 0.2847043 -> Al ser un valor bajo indica que el porcentaje de error es despreciable.

# Metricas normalizadas

STC1 = sum((result$Real-(mean(result$Real)))^2)
STC1 

SCR1 = STC1-SCE1
SCR1  

r21 = SCR1/STC1
r21 # 0.9188792 -> El valor aproximado al 1, describe un buen modelo.

r2a1 = 1-(1-r21)*(length(result$Real)-1)/(length(result$Real)-(dim(test)[2]-1))
r2a1 # 0.9187505 -> Describe un excelente modelo.
# El "R cuadrado ajustado" porque es regresion multiple.
# Ideal para un control preventivo de la produccion.

proc.time() - tiempoANN

# user  system elapsed 
# 2.94    0.22   81.75 

# user: tiempo de la CPU dedicado a la ejecucion de las instrucciones del proceso [segundos].
# system: tiempo de la CPU empleado por el sistema operativo [segundos].
# elapsed: tiempo transcurrido real desde que se inicio el proceso [segundos].

#################################
# Support Vector Machines - SVM #  
#################################

tiempoSVM <- proc.time()


# Regresion Lineal Multiple (Metodo Clasico)

xA = Turbina$Wind.Speed..m.s.
xB = Turbina$Theoretical_Power_Curve..KWh.
xC = Turbina$Wind.Direction....
yA = Turbina$LV.ActivePower..kW.

reg = lm(yA~xA+xB+xC)

yest = reg$coefficients[1]+reg$coefficients[2]*xA+reg$coefficients[3]*xB+reg$coefficients[4]*xC
error1 = yA-yest
SCE1 = sum(error1^2)
SCE1 #8223964913 Error de todo el modelo.

# Regresion mediante SVM

regS = svm(formula = y~., data = train, 
           type = 'eps-regression', kernel = 'linear')
yestS = predict(regS, type = 'response', 
                newdata = test[,-c(1)])

yrealS = test[,-c(1,2,3,5)] 

errorS = yrealS-yestS


SCES = sum(errorS^2)
SCES #4078397582

MAES = mae(yrealS,yestS)
MAES #1329.732

MSES = mse(yrealS,yestS)
MSES #3229135

RMSES = rmse(yrealS,yestS)
RMSES #1796.979

STCS = sum((yrealS-(mean(yrealS)))^2)
STCS #10869506

SCRS = STCS-SCES
SCRS #-4067528076

r2S = SCRS/STCS
r2S #-375.4896

r2aS = 1-(1-r2S)*((length(yestS)-1)/(length(yestS)-3-1))
r2aS #-375.1087

proc.time() - tiempoSVM
# user  system elapsed 
# 1.16    0.26  241.89 

# user: tiempo de la CPU dedicado a la ejecucion de las instrucciones del proceso [segundos].
# system: tiempo de la CPU empleado por el sistema operativo [segundos].
# elapsed: tiempo transcurrido real desde que se inicio el proceso [segundos].
